{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59c826aa-eeef-4da2-8f86-6748b579b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re , PyPDF2\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6b1f2d-ae76-42ec-8af6-22f7aa8b9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text_all_pages(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        full_text = \"\"\n",
    "        # Loop through all pages\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            full_text += page.extract_text() + \"\\n\"\n",
    "        return full_text\n",
    "def extract_text_from_multiple_pdfs(directory_path):\n",
    "    all_text = \"\"\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(directory_path, filename)\n",
    "            pdf_text = extract_pdf_text_all_pages(pdf_path)\n",
    "            all_text += f\"--- Text from {filename} ---\\n\" + pdf_text + \"\\n\"\n",
    "    return all_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8dcecd6-6695-4c3a-bc32-315920b47074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad502845-00bf-402a-ae7d-a8402a6e00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_length=1000):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + max_length]) for i in range(0, len(words), max_length)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ed55e97-2ea3-4420-ac86-594d7908090b",
   "metadata": {},
   "outputs": []
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "qa_model = pipeline(\"question-answering\", model=model_name, device=0)  # device=0 for GPU, device=-1 for CPU\n",
    "def get_answers_from_text(question, context):\n",
    "    return qa_model(question=question, context=context)\n",
    "def process_text_in_chunks(question, text_chunks):\n",
    "    answers = []\n",
    "    for chunk in text_chunks:\n",
    "        result = get_answers_from_text(question, chunk)\n",
    "        answers.append(result['answer'])\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers_to_file(answers, output_file=\"answers.txt\"):\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for i, answer in enumerate(answers):\n",
    "            file.write(f\"Answer from chunk {i+1}: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from chunk 1: NEBTS method\n"
     ]
    }
   ],
   "source": [
    "def main(directory_path, question):\n",
    "    all_pdfs_text = extract_text_from_multiple_pdfs(directory_path)\n",
    "    preprocessed_text = preprocess_text(all_pdfs_text)\n",
    "    text_chunks = chunk_text(preprocessed_text, max_length=1000)\n",
    "    answers = process_text_in_chunks(question, text_chunks)\n",
    "    save_answers_to_file(answers)\n",
    "    for i, answer in enumerate(answers):\n",
    "        print(f\"Answer from chunk {i+1}: {answer}\")\n",
    "directory_path = './'  # Replace with your PDF folder path\n",
    "question = \"What is ORCA\"\n",
    "main(directory_path, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b330f7",
   "metadata": {},
   "source": [
    "# All in single cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c865e-9cfb-46fc-880e-4f84f83e4ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from chunk 1: NEBTS method\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import PyPDF2\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "def extract_pdf_text_all_pages(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        full_text = \"\"\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            full_text += page.extract_text() + \"\\n\"\n",
    "        return full_text\n",
    "def extract_text_from_multiple_pdfs(directory_path):\n",
    "    all_text = \"\"\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(directory_path, filename)\n",
    "            pdf_text = extract_pdf_text_all_pages(pdf_path)\n",
    "            all_text += f\"--- Text from {filename} ---\\n\" + pdf_text + \"\\n\"\n",
    "    return all_text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def chunk_text(text, max_length=1000):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + max_length]) for i in range(0, len(words), max_length)]\n",
    "    return chunks\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", device=device)\n",
    "\n",
    "def get_answers_from_text(question, context):\n",
    "    return qa_model(question=question, context=context)\n",
    "def process_text_in_chunks(question, text_chunks):\n",
    "    answers = []\n",
    "    for chunk in text_chunks:\n",
    "        result = get_answers_from_text(question, chunk)\n",
    "        answers.append(result['answer'])\n",
    "    return answers\n",
    "\n",
    "def main(directory_path, question):\n",
    "    all_pdfs_text = extract_text_from_multiple_pdfs(directory_path)\n",
    "    preprocessed_text = preprocess_text(all_pdfs_text)\n",
    "    text_chunks = chunk_text(preprocessed_text, max_length=1000)\n",
    "    answers = process_text_in_chunks(question, text_chunks)\n",
    "    \n",
    "    for i, answer in enumerate(answers):\n",
    "        print(f\"Answer from chunk {i+1}: {answer}\")\n",
    "\n",
    "directory_path = './'  # Replace with your PDF folder path\n",
    "question = \"What is ORCA \"\n",
    "main(directory_path, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b74e5",
   "metadata": {},
   "source": [
    "# Transformers on single paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f8704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is ORCA\n",
      "Answer: NEB-TS method\n",
      "\n",
      "Question: What details can you extract from the text?\n",
      "Answer: QST2+IRC method in Gaussian 16\n",
      "\n",
      "Question: How does the paragraph relate to the topic?\n",
      "Answer: double zeta quality\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\")\n",
    "paragraph = \"\"\"\n",
    "For the geometrical optimization of the reactant and product states, and the TS, you should use the B3LYP functional along with the D3 version of Grimmeâ€™s dispersion correction with Becke- Johnson damping. You should use the def2-SVP basis set that is of double zeta quality. You should use the SMD solvent model to emulate the experimental conditions. You should employ tight convergence criteria for geometrical optimization and TS search. You can use either the NEB-TS method in ORCA or the QST2+IRC method in Gaussian 16.\n",
    "\"\"\"\n",
    "questions = [\n",
    "    \"What is ORCA\",\n",
    "    \"What details can you extract from the text?\",\n",
    "    \"How does the paragraph relate to the topic?\",\n",
    "    # Add more questions as needed\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_pipeline(question=question, context=paragraph)\n",
    "    print(f\"Question: {question}\\nAnswer: {result['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767de00b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58b44ee0",
   "metadata": {},
   "source": [
    "#### collected By : Amar Raj Ghimire\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25e95cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
